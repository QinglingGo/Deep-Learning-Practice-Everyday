{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据集下载\n",
    "\n",
    "路透社数据集是关于新闻的多类文本分类数据集，可以被划分为46个不同的主题。每个主题的样本数量不同，但是每个主题的训练集中至少有10个样本。取数据集中出现频率最高的前10000个单词组成词典，构建单词和索引的映射："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  8982\n",
      "test data:  2246\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "print('train data: ', len(train_data))\n",
    "print('test data: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10th data in train dataset: \n",
      " [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print('The 10th data in train dataset: \\n', train_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将索引解析为单词\n",
    "\n",
    "# word_index是一个将单词映射为整数索引的字典\n",
    "word_index = reuters.get_word_index()\n",
    "# 键值颠倒，将整数映射为单词，构建reverse_word_index字典\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 解码第一条评论，将索引值减去３，因为前三个数字默认为'padding', 'start of sequence', 'unknown'的保留索引值\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the decoded review: \n",
      " ? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "print('the decoded review: \\n', decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    # 先构造一个形状为(len(sequences), dimension)的全０矩阵\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    # 根据序列的查询,将result[i]指定的索引设置为１\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 将训练数据和测试数据进行one-hot编码\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用one-hot对labels进行分类数据向量化，即只有符合类别标签的位置是1,其余位置是0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (8982, 10000)\n",
      "test data shape:  (2246, 10000)\n",
      "train label shape:  (8982, 46)\n",
      "test label shape:  (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print('train data shape: ', x_train.shape)\n",
    "print('test data shape: ', x_test.shape)\n",
    "print('train label shape: ', one_hot_train_labels.shape)\n",
    "print('test label shape: ', one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 构建神经网络\n",
    "\n",
    "因为需要对46个类别进行分类，所以中间的隐层的维度需要进行相应的扩充，使用64个隐层节点构建神经网络。\n",
    "\n",
    "输出层使用softmax作为激活函数。output[i]是样本属于第i类的概率，46类的概率总和是１。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型，使用categorical_crossentropy（分类交叉熵）作为损失函数，用于衡量两个类别之间的概率分布距离\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 测试神经网络\n",
    "\n",
    "取1000个样本作为训练时的验证集，剩下的作为训练集。训练采用20epochs,使用512个样本进行小批次训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 194us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.7034 - acc: 0.8472 - val_loss: 0.9844 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.5667 - acc: 0.8802 - val_loss: 0.9411 - val_acc: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.4581 - acc: 0.9048 - val_loss: 0.9083 - val_acc: 0.8020\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.3695 - acc: 0.9231 - val_loss: 0.9363 - val_acc: 0.7890\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.3032 - acc: 0.9315 - val_loss: 0.8917 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.2537 - acc: 0.9414 - val_loss: 0.9071 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.2187 - acc: 0.9471 - val_loss: 0.9177 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1873 - acc: 0.9508 - val_loss: 0.9027 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 0.1703 - acc: 0.9521 - val_loss: 0.9323 - val_acc: 0.8110\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1536 - acc: 0.9554 - val_loss: 0.9689 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1390 - acc: 0.9560 - val_loss: 0.9686 - val_acc: 0.8150\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1313 - acc: 0.9560 - val_loss: 1.0220 - val_acc: 0.8060\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1217 - acc: 0.9579 - val_loss: 1.0254 - val_acc: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1198 - acc: 0.9582 - val_loss: 1.0430 - val_acc: 0.8060\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1138 - acc: 0.9597 - val_loss: 1.0955 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 0.1111 - acc: 0.9593 - val_loss: 1.0674 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制条目之间的关系图：\n",
    "\n",
    "__训练损失和验证损失__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f89c93f78d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "acc = history.history['acc']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__训练准确率和测试准确率__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 减少训练轮数，再次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/8\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
      "Epoch 3/8\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
      "Epoch 4/8\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
      "Epoch 5/8\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
      "Epoch 6/8\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 0.5124 - acc: 0.8921 - val_loss: 0.9102 - val_acc: 0.8140\n",
      "Epoch 7/8\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 0.4124 - acc: 0.9137 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/8\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 0.3355 - acc: 0.9290 - val_loss: 0.8732 - val_acc: 0.8260\n",
      "2246/2246 [==============================] - 0s 61us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=8,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9845061219386086, 0.7836153161175423]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练８轮的模型可以在测试集上获得78%的准确率，对于46类问题已经属于比较理想的分类结果。对于完全随机的路透社数据集分类,将获得19%的分类准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19679430097951914"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在新的数据上预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions是测试数据的分类结果，对于每一个测试数据都是46维的vector,且总和应该等于１。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在46维vector中，数字最大的一类是最终预测的类别："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 减少隐层维度，重新测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 64us/step - loss: 2.7073 - acc: 0.4411 - val_loss: 2.0155 - val_acc: 0.5930\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 1.7341 - acc: 0.6183 - val_loss: 1.6573 - val_acc: 0.6100\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 0s 44us/step - loss: 1.4678 - acc: 0.6359 - val_loss: 1.5688 - val_acc: 0.6080\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 1.3273 - acc: 0.6446 - val_loss: 1.4833 - val_acc: 0.6170\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 1.2168 - acc: 0.6498 - val_loss: 1.4540 - val_acc: 0.6250\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 1.1265 - acc: 0.6753 - val_loss: 1.4326 - val_acc: 0.6350\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 0s 42us/step - loss: 1.0522 - acc: 0.6944 - val_loss: 1.4520 - val_acc: 0.6420\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 0s 42us/step - loss: 0.9927 - acc: 0.7037 - val_loss: 1.4426 - val_acc: 0.6510\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 0s 42us/step - loss: 0.9425 - acc: 0.7167 - val_loss: 1.4766 - val_acc: 0.6500\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 0s 42us/step - loss: 0.8978 - acc: 0.7429 - val_loss: 1.5227 - val_acc: 0.6480\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.8602 - acc: 0.7547 - val_loss: 1.5150 - val_acc: 0.6670\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.8261 - acc: 0.7602 - val_loss: 1.5255 - val_acc: 0.6690\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.7962 - acc: 0.7677 - val_loss: 1.5737 - val_acc: 0.6660\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.7717 - acc: 0.7734 - val_loss: 1.6052 - val_acc: 0.6640\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.7449 - acc: 0.7814 - val_loss: 1.6424 - val_acc: 0.6690\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.7237 - acc: 0.7886 - val_loss: 1.7200 - val_acc: 0.6650\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 0s 47us/step - loss: 0.7052 - acc: 0.7964 - val_loss: 1.7392 - val_acc: 0.6640\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 0s 45us/step - loss: 0.6849 - acc: 0.8022 - val_loss: 1.7847 - val_acc: 0.6670\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 0s 43us/step - loss: 0.6680 - acc: 0.8086 - val_loss: 1.7986 - val_acc: 0.6700\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 0s 42us/step - loss: 0.6532 - acc: 0.8158 - val_loss: 1.8293 - val_acc: 0.6680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89c9dbc5c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当中间的隐层节点减少时，最后的准确率也会随之下降，说明当数据分类情况比较复杂时，中间需要足够的隐层维度才能保证充分学习到数据特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
