{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "WARNING:tensorflow:From /home/hu/Documents/OneDrive/CurrentProject/DLandTF/JupyterNotebook/cifar10/cifar10_input.py:232: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/hu/Documents/OneDrive/CurrentProject/DLandTF/JupyterNotebook/cifar10/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hu/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py:1241: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/hu/Documents/OneDrive/CurrentProject/DLandTF/JupyterNotebook/cifar10/cifar10_input.py:132: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "begin data\n"
     ]
    }
   ],
   "source": [
    "#取数据\n",
    "batch_size = 128\n",
    "workPath = os.getcwd()\n",
    "data_dir = 'tmp/cifar10_data/cifar-10-batches-bin'\n",
    "dest_directory = os.path.join(workPath, data_dir)\n",
    "print(\"begin\")\n",
    "images_train, labels_train = cifar10_input.inputs(eval_data = False,data_dir = dest_directory, batch_size = batch_size)\n",
    "images_test, labels_test = cifar10_input.inputs(eval_data = True, data_dir = dest_directory, batch_size = batch_size)\n",
    "print(\"begin data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "  \n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')  \n",
    "                        \n",
    "def avg_pool_6x6(x):\n",
    "  return tf.nn.avg_pool(x, ksize=[1, 6, 6, 1],\n",
    "                        strides=[1, 6, 6, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 24,24,3]) # cifar data image of shape 24*24*3\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 数字=> 10 classes\n",
    "\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 3, 64])\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,24,24,3])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "#######################################################多卷积核\n",
    "W_conv2_5x5 = weight_variable([5, 5, 64, 64]) \n",
    "b_conv2_5x5 = bias_variable([64]) \n",
    "W_conv2_7x7 = weight_variable([7, 7, 64, 64]) \n",
    "b_conv2_7x7 = bias_variable([64]) \n",
    "\n",
    "W_conv2_3x3 = weight_variable([3, 3, 64, 64]) \n",
    "b_conv2_3x3 = bias_variable([64]) \n",
    "\n",
    "W_conv2_1x1 = weight_variable([1, 1, 64, 64]) \n",
    "b_conv2_1x1 = bias_variable([64]) \n",
    "\n",
    "h_conv2_1x1 = tf.nn.relu(conv2d(h_pool1, W_conv2_1x1) + b_conv2_1x1)\n",
    "h_conv2_3x3 = tf.nn.relu(conv2d(h_pool1, W_conv2_3x3) + b_conv2_3x3)\n",
    "h_conv2_5x5 = tf.nn.relu(conv2d(h_pool1, W_conv2_5x5) + b_conv2_5x5)\n",
    "h_conv2_7x7 = tf.nn.relu(conv2d(h_pool1, W_conv2_7x7) + b_conv2_7x7)\n",
    "h_conv2 = tf.concat([h_conv2_5x5,h_conv2_7x7,h_conv2_3x3,h_conv2_1x1],3)\n",
    "\n",
    "#######################################################\n",
    "#W_conv2 = weight_variable([5, 5, 64, 64])\n",
    "#b_conv2 = bias_variable([64])\n",
    "#\n",
    "#h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "#######################################################\n",
    "\n",
    "W_conv3 = weight_variable([5, 5, 256, 10])\n",
    "b_conv3 = bias_variable([10])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "\n",
    "nt_hpool3=avg_pool_6x6(h_conv3)#10\n",
    "nt_hpool3_flat = tf.reshape(nt_hpool3, [-1, 10])\n",
    "y_conv=tf.nn.softmax(nt_hpool3_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))\n",
    "\n",
    "#不同的优化方法测测效果\n",
    "#train_step = tf.train.GradientDescentOptimizer(1e-3).minimize(cross_entropy)\n",
    "#train_step = tf.train.AdagradOptimizer(1e-5).minimize(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-f948ea1d3220>:3: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "step 0, training accuracy 0.0703125\n",
      "step 200, training accuracy 0.375\n",
      "step 400, training accuracy 0.429688\n",
      "step 600, training accuracy 0.453125\n",
      "step 800, training accuracy 0.476562\n",
      "step 1000, training accuracy 0.382812\n",
      "step 1200, training accuracy 0.554688\n",
      "step 1400, training accuracy 0.5625\n",
      "step 1600, training accuracy 0.5\n",
      "step 1800, training accuracy 0.460938\n",
      "step 2000, training accuracy 0.585938\n",
      "step 2200, training accuracy 0.539062\n",
      "step 2400, training accuracy 0.617188\n",
      "step 2600, training accuracy 0.585938\n",
      "step 2800, training accuracy 0.585938\n",
      "step 3000, training accuracy 0.539062\n",
      "step 3200, training accuracy 0.539062\n",
      "step 3400, training accuracy 0.609375\n",
      "step 3600, training accuracy 0.609375\n",
      "step 3800, training accuracy 0.625\n",
      "step 4000, training accuracy 0.570312\n",
      "step 4200, training accuracy 0.578125\n",
      "step 4400, training accuracy 0.625\n",
      "step 4600, training accuracy 0.726562\n",
      "step 4800, training accuracy 0.679688\n",
      "step 5000, training accuracy 0.695312\n",
      "step 5200, training accuracy 0.585938\n",
      "step 5400, training accuracy 0.664062\n",
      "step 5600, training accuracy 0.59375\n",
      "step 5800, training accuracy 0.65625\n",
      "step 6000, training accuracy 0.585938\n",
      "step 6200, training accuracy 0.640625\n",
      "step 6400, training accuracy 0.59375\n",
      "step 6600, training accuracy 0.671875\n",
      "step 6800, training accuracy 0.671875\n",
      "step 7000, training accuracy 0.664062\n",
      "step 7200, training accuracy 0.71875\n",
      "step 7400, training accuracy 0.648438\n",
      "step 7600, training accuracy 0.609375\n",
      "step 7800, training accuracy 0.679688\n",
      "step 8000, training accuracy 0.625\n",
      "step 8200, training accuracy 0.617188\n",
      "step 8400, training accuracy 0.726562\n",
      "step 8600, training accuracy 0.703125\n",
      "step 8800, training accuracy 0.703125\n",
      "step 9000, training accuracy 0.710938\n",
      "step 9200, training accuracy 0.71875\n",
      "step 9400, training accuracy 0.773438\n",
      "step 9600, training accuracy 0.6875\n",
      "step 9800, training accuracy 0.679688\n",
      "step 10000, training accuracy 0.6875\n",
      "step 10200, training accuracy 0.734375\n",
      "step 10400, training accuracy 0.734375\n",
      "step 10600, training accuracy 0.695312\n",
      "step 10800, training accuracy 0.679688\n",
      "step 11000, training accuracy 0.789062\n",
      "step 11200, training accuracy 0.625\n",
      "step 11400, training accuracy 0.710938\n",
      "step 11600, training accuracy 0.695312\n",
      "step 11800, training accuracy 0.695312\n",
      "step 12000, training accuracy 0.726562\n",
      "step 12200, training accuracy 0.671875\n",
      "step 12400, training accuracy 0.664062\n",
      "step 12600, training accuracy 0.695312\n",
      "step 12800, training accuracy 0.757812\n",
      "step 13000, training accuracy 0.71875\n",
      "step 13200, training accuracy 0.703125\n",
      "step 13400, training accuracy 0.75\n",
      "step 13600, training accuracy 0.679688\n",
      "step 13800, training accuracy 0.757812\n",
      "step 14000, training accuracy 0.734375\n",
      "step 14200, training accuracy 0.6875\n",
      "step 14400, training accuracy 0.789062\n",
      "step 14600, training accuracy 0.765625\n",
      "step 14800, training accuracy 0.679688\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "for i in range(15000):#20000\n",
    "  image_batch, label_batch = sess.run([images_train, labels_train])\n",
    "  label_b = np.eye(10,dtype=float)[label_batch] #one hot\n",
    "  \n",
    "  train_step.run(feed_dict={x:image_batch, y: label_b},session=sess)\n",
    "  \n",
    "  if i%200 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:image_batch, y: label_b},session=sess)\n",
    "    print( \"step %d, training accuracy %g\"%(i, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished！ test accuracy 0.664062\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = sess.run([images_test, labels_test])\n",
    "label_b = np.eye(10,dtype=float)[label_batch]#one hot\n",
    "print (\"finished！ test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "     x:image_batch, y: label_b},session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
